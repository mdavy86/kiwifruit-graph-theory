---
title: "Visualise fresh weight"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## https://github.com/patricksnelgar/kiwifruit-graph-theory/blob/master/code/exploration.Rmd

library(readr)
library(dplyr)
library(magrittr)
library(here)
library(lubridate)
library(lattice)
library(lme4)
library(insight)
library(ggplot2)
library(paramtest)
library(pwr)


# relational information for each of the quadrants
quadrant_info <- 
	data.frame(Quadrant = 1:36,
			   OffsetX = rep(c(1000, 500, 0, 0, 500, 1000), each = 6),
			   OffsetY = rep(c(2000, 1000, 0, 0, 1000, 2000), 6),
			   MultiplierX = rep(c(-1,1), each = 18),
			   MultiplierY = rep(rep(c(-1,1), each = 3), 6),
			   QuadrantFromLeader = rep(c(3:1, 1:3), 6), 
			   QuadrantFromTrunk = rep(c(3:1, 1:3), each = 6),
			   NorthSouth = rep(c("S", "N"), each = 18),
			   EastWest = rep(rep(
		   						  c("W", "E"), 
		   						  each = 3
		   						  ),
			   			   	  6)
			   )
# x&y coords for overlaying the quadrant IDs
# only works when vine is plotted with leader running horizontal (swap x and y).
quadrant_labels <- data.frame(x = rep(c(-1250, -750, -250, 250, 750, 1250), each = 6),
							  y = rep(c(2500, 1500, 500, -500, -1500, -2500), 6),
							  label = 1:36)
flowering_dates <- read_csv(here("input/flowering_dates.csv")) %>%
					mutate(FloweringColour = tolower(FloweringColour),
						   FloweringDate = dmy(FloweringDate))

source("../data_import/architecture_data_import_and_merge.R")
source("../data_import/shoot_leaf_area_import_and_plot.R")
source("../data_import/shoot_data_import_and_merge.R")
source("../data_import/fruit_data_import_and_merge.R")

## Add factors
all_fruit_data <- within(all_fruit_data, VineUUID <- factor(VineUUID, levels=unique(VineUUID), labels= paste("Vine", unique(VineUUID))))
```


## Background

Kris Kramer-Walter and Patrick Snelgar have conducted a study of 9 G3 vines from flowering 
fruit harvest, the entire population of fruit were stripped off each vine in 2020, 
fruit were then destructively assessed in the fast lab. Three different canopy
structure treatments (Conventional Spur, Strung) were replicated over three vines.

This data set provides the entire population of fruit weights in 2020, and the underlying
sampling distribution for G3, a control for the Gold programme. From this data set we can
examine the underlying within vine variability of fruit weights;

Tabulating Numbers of fruit per vine assessed by Vine and Treatment;

```{r}
knitr::kable(with(all_fruit_data, table(VineUUID, VineTreatmentNoNumber)))
```

## Exploratory analysis

Visualizing the Fresh weight using histograms, conditioned on each Vine, Treatment, and collapsed over Vines;

```{r}
histogram(~ FreshWeight | VineUUID, data=all_fruit_data, scales=list(alternating=FALSE), between=list(x=0.3, y=0.3),
          breaks=30, layout=c(3,3), panel=function(x, subscripts, groups, ...){
            panel.histogram(x, ...)
            panel.abline(v=90, lty=3, col="red", lwd=1.5)
            thres_frac <- sum(x<=90, na.rm=TRUE) / length(x)
            panel.text(50, 12, paste0(round(100*thres_frac,2), "%"), cex=0.5)
          })

histogram(~ FreshWeight | VineTreatmentNoNumber, data=all_fruit_data,
          aspect=1, main="Collapsing over replicate Vines", 
          scales=list(alternating=FALSE), between=list(x=0.3, y=0.3), breaks=30, layout=c(3,1), panel=function(x, subscripts, groups, ...){
            panel.histogram(x, ...)
            panel.abline(v=90, lty=3, col="red", lwd=1.5)
            thres_frac <- sum(x<=90, na.rm=TRUE) / length(x)
            panel.text(50, 10, paste0(round(100*thres_frac,2), "%"), cex=0.6)
          })

histogram(~ FreshWeight, data=all_fruit_data, scales=list(alternating=FALSE), 
          between=list(x=0.3, y=0.3), breaks=30, main="Collapsing over all Vines",
          panel=function(x, subscripts, groups, ...){
            panel.histogram(x, ...)
            panel.abline(v=90, lty=3, col="red", lwd=1.5)
            thres_frac <- sum(x<=90, na.rm=TRUE) / length(x)
            panel.text(50, 10, paste0(round(100*thres_frac,2), "%"))
          })
```


## Summary statistics

Summary statistics for each vine;

```{r}
sum_vine <- cbind(Vine=levels(all_fruit_data$VineUUID), unname(do.call(rbind.data.frame, with(all_fruit_data, tapply(FreshWeight,  VineUUID, summary)))))
colnames(sum_vine) <- c("Vine", "Min", "1st Qu", "Median","Mean", "3rd Qu", "Max", "NA's")
knitr::kable(sum_vine)
```

Standard deviations within Vines;

```{r}
sd_vine <- with(all_fruit_data, tapply(FreshWeight,  VineUUID, sd, na.rm=TRUE))
knitr::kable(sd_vine,  col.names=c("sd(X)"))
```

The range of standard deviations across the 9 Vines is;

```{r}
range(sd_vine)
```

and the average [RMS](https://en.wikipedia.org/wiki/Root_mean_square) standard deviation is;

```{r}
sqrt(mean(sd_vine^2))
```

These summary statistics appear to be consistent with 
[Kiwifruit fruit size distributions, K. J. McAneney, A. C. Richardson, A. E. Green](https://www.tandfonline.com/doi/pdf/10.1080/01140671.1989.10428047)


The coefficient of variation is a useful metric, a value closer to 0 indicates higher signal to noise ratio.

```{r}
with(all_fruit_data, tapply(FreshWeight,  VineUUID, sd, na.rm=TRUE) / 
       tapply(FreshWeight,  VineUUID, mean, na.rm=TRUE))
```

For different Genotypes within families with smaller fruit sizes, a reasonable assumption to make is that the coefficient of variation would be similar to coefficient of variation values observed above.

<img src="sd_vs_mean.png">


## Statistical Power

Using underlying standard deviation information we can estimate statistical power based on a desired difference to detect.


```{r echo=FALSE}
m1     <- 0          # mu H0
sd1    <- sd2 <- 1.5 # sigma H0, HA
m2     <- 3.5        # mu HA
alpha  <- 0.05
z_crit <- qnorm(1-(alpha/2), m1, sd1)

# set length of tails
min1 <- m1-sd1*4
max1 <- m1+sd1*4
min2 <- m2-sd2*4
max2 <- m2+sd2*4

# create x sequence
x   <- seq(min(min1,min2), max(max1, max2), .01)
# generate normal dist #1
y1  <- dnorm(x, m1, sd1)
# put in data frame
df1 <- data.frame("x" = x, "y" = y1)
# generate normal dist #2
y2  <- dnorm(x, m2, sd2)
# put in data frame
df2 <- data.frame("x" = x, "y" = y2)

# Alpha polygon
y.poly <- pmin(y1,y2)
poly1  <- data.frame(x=x, y=y.poly)
poly1  <- poly1[poly1$x >= z_crit, ]
poly1  <- rbind(poly1, c(z_crit, 0))  # add lower-left corner

# Beta polygon
poly2 <- df2
poly2 <- poly2[poly2$x <= z_crit,]
poly2 <- rbind(poly2, c(z_crit, 0))  # add lower-left corner

# power polygon; 1-beta
poly3 <- df2
poly3 <- poly3[poly3$x >= z_crit,]
poly3 <- rbind(poly3, c(z_crit, 0))  # add lower-left corner

# combine polygons
poly1$id <- 3 # alpha, give it the highest number to make it the top layer
poly2$id <- 2 # beta
poly3$id <- 1 # power; 1 - beta
poly     <- rbind(poly1, poly2, poly3)
poly$id  <- factor(poly$id,  labels=c("power","beta","alpha"))

# plot with ggplot2
suppressWarnings({
  tweak <- 0.4
  out   <- ggplot(poly, aes(x,y, fill=id, group=id))                                         +
    geom_polygon(show_guide=F, alpha=I(8/10))                                                + # add line for treatment group
    geom_line(data=df1, aes(x,y, color="H0", group=NULL, fill=NULL), size=1.5, show_guide=F) + # add line for treatment group
    geom_line(data=df2, aes(color="HA", group=NULL, fill=NULL),size=1.5, show_guide=F)       + # add vlines for z_crit
    geom_vline(xintercept = 0, size=1, linetype="dashed")                                    +
    geom_vline(xintercept = z_crit, size=1, linetype="dashed")                               + # change colors
    scale_color_manual("Group",
                       values= c("HA" = "#981e0b","H0" = "black")) +
    scale_fill_manual("test",
                      values= c("alpha" = "#0d6374","beta" = "#be805e","power"="#7cecee"))   + # beta arrow
    annotate("segment", x=0.1+tweak, y=0.045, xend=1.3+tweak, yend=0.01,
             arrow = arrow(length = unit(0.3, "cm")), size=1)                                +
    annotate("text", label="beta", x=0+tweak, y=0.05, parse=T, size=8)                       + # alpha arrow
    annotate("segment", x=4, y=0.043, xend=3.4, yend=0.01,
             arrow = arrow(length = unit(0.3, "cm")), size=1)                                +
    annotate("text", label="alpha", x=4.2, y=0.05, parse=T, size=8)                          + # power arrow
    annotate("segment", x=6, y=0.2, xend=4.5, yend=0.15,
             arrow = arrow(length = unit(0.3, "cm")), size=1)                                +
    annotate("text", label="1-beta", x=6.1, y=0.21, parse=T, size=8)                         + # H_0 title
    annotate("text", label="H[0]", x=m1+tweak, y=0.28, parse=T, size=8)                      + # H_a title
    annotate("text", label="H[a]", x=m2, y=0.28, parse=T, size=8)                            + # delta
    annotate("text", label="Delta", x=(z_crit-m1)/2, y=-0.01, parse=T, size=8)               +
    annotate("segment", x=(z_crit-m1)/2 - 0.2, y=-0.01, xend=m1+0.2,
             yend=-0.01, arrow = arrow(length = unit(0.3, "cm")), size=1)                    +
    annotate("segment", x=(z_crit-m1)/2 + 0.2, y=-0.01, xend=z_crit-0.2,
             yend=-0.01, arrow = arrow(length = unit(0.3, "cm")), size=1)                    + # remove some elements
    #  ggtitle("Statistical Power Plots, Textbook-style") +
    theme(panel.grid.minor = element_blank(),
          panel.grid.major = element_blank(),
          panel.background = element_blank(),
          plot.background  = element_rect(),
          panel.border     = element_blank(),
          axis.line        = element_blank(),
          axis.text.x      = element_blank(),
          axis.text.y      = element_blank(),
          axis.ticks       = element_blank(),
          axis.title.x     = element_blank(),
          axis.title.y     = element_blank(),
          plot.title       = element_text(size=22))
})
ggsave("power.png", height=8, width=13, dpi=72)
```

<img src="power.png">

Assuming we have a sample to compare to G3 as a positive control, and the variability is similar, we can estimate power required using a two sided t-test to examine if there is a statistical difference between the samples. Using the empirical median standard deviation which is the standard deviation for at least 50% of the samples;

Sampling n=60;

```{r}
delta <- 1:20
    n <- 60

min_sd <- min(sd_vine)    
rms_sd <- sqrt(mean(sd_vine^2))
max_sd <- max(sd_vine)
type  <- "one.sample"
alt   <- "one.sided"

delta_min <- lapply(delta, function(x)power.t.test(n=n, sd=min_sd, sig.level=0.05, delta=x,
                                                   type=type, alternative=alt))
delta_rms <- lapply(delta, function(x)power.t.test(n=n, sd=rms_sd, sig.level=0.05, delta=x,
                                                   type=type, alternative=alt))
delta_max <- lapply(delta, function(x)power.t.test(n=n, sd=max_sd, sig.level=0.05, delta=x,
                                                   type=type, alternative=alt))


plot(delta, sapply(delta_rms, function(x)x$power), type="l", col="grey", ylab="Statistical power", main=substitute(paste("n=", n, ", rms ", hat(sigma)==x), list(n=n, x=round(rms_sd, 2))))
lines(delta, sapply(delta_min, function(x)x$power), col="green")
lines(delta, sapply(delta_max, function(x)x$power), col="red")

grid()
legend("topleft",legend = c("max", "rms", "min"), col=c("red","grey", "green"), lty=1, bty="n")
```

Tabulating;

```{r}
knitr::kable(data.frame(Delta=delta,
           min_sd = round(sapply(delta_min, function(x)x$power),3),
           rms_sd = round(sapply(delta_rms, function(x)x$power),3),
           max_sd = round(sapply(delta_max, function(x)x$power),3)
))
```


Sampling n=40;

```{r}
delta <- 1:20
    n <- 40

min_sd <- min(sd_vine)    
rms_sd <- sqrt(mean(sd_vine^2))
max_sd <- max(sd_vine)
type  <- "one.sample"
alt   <- "one.sided"

delta_min <- lapply(delta, function(x)power.t.test(n=n, sd=min_sd, sig.level=0.05, delta=x,
                                                   type=type, alternative=alt))
delta_rms <- lapply(delta, function(x)power.t.test(n=n, sd=rms_sd, sig.level=0.05, delta=x,
                                                   type=type, alternative=alt))
delta_max <- lapply(delta, function(x)power.t.test(n=n, sd=max_sd, sig.level=0.05, delta=x,
                                                   type=type, alternative=alt))


plot(delta, sapply(delta_rms, function(x)x$power), type="l", col="grey", ylab="Statistical power", main=substitute(paste("n=", n, ", rms ", hat(sigma)==x), list(n=n, x=round(rms_sd, 2))))
lines(delta, sapply(delta_min, function(x)x$power), col="green")
lines(delta, sapply(delta_max, function(x)x$power), col="red")

grid()
legend("topleft",legend = c("max", "rms", "min"), col=c("red","grey", "green"), lty=1, bty="n")
```

Tabulating;

```{r}
knitr::kable(data.frame(Delta=delta,
           min_sd = round(sapply(delta_min, function(x)x$power),3),
           rms_sd = round(sapply(delta_rms, function(x)x$power),3),
           max_sd = round(sapply(delta_max, function(x)x$power),3)
))
```

## Estimating variance components

Using lmer to obtain a reml model;

```{r}
m2 <- lmer(FreshWeight ~ VineTreatmentNoNumber + (VineTreatmentNoNumber | VineUUID), data=all_fruit_data)
summary(m2)
```


### Fixed effects

Investigating methods, conventional is slightly better than Spur which is slightly better than Strung.

```{r}
 get_parameters(m2)
```


### Random effects

Variance components between Vines (3 per Treatment level) within Treatments;

```{r}
c(get_variance_intercept(m2), get_variance_slope(m2))
```


Residual standard deviation within Vines is;

```{r}
sqrt(unname(get_variance_residual(m2)))
```


## Sampling Distribution

As we have the entire population of fruit picked and assessed for these 9 Vines,
we have the underlying sampling distribution. This distribution visually appears 
similar to an underlying normal distribution, testing for normality using normal
Q-Q plots conditioned by Vine;

```{r}
qqmath(~ FreshWeight | VineUUID, data=all_fruit_data,
       distribution = function(p) qnorm(p, mean=0, sd=1), main="Normal Q-Q Plot",
       ylab="Sample Quantiles", xlab="Theoretical quantiles",
       scales=list(alternating=FALSE), between=list(x=0.3, y=0.3),
       breaks=30, layout=c(3,3), pch=16, cex=0.5, aspect=1,
      prepanel = prepanel.qqmathline,
       panel = function(x, ...) {
         panel.qqmath(x, ...)
         panel.qqmathline(x, ...)
       })
```

Testing for normality using normal Q-Q plots by Treatment collapsing over replicates;

```{r}
qqmath(~ FreshWeight | VineTreatmentNoNumber, data=all_fruit_data,
       distribution = function(p) qnorm(p, mean=0, sd=1), main="Normal Q-Q Plot",
       ylab="Sample Quantiles", xlab="Theoretical quantiles",
       scales=list(alternating=FALSE), between=list(x=0.3, y=0.3),
       breaks=30, layout=c(3,1), pch=16, cex=0.5, aspect=1,
      prepanel = prepanel.qqmathline,
       panel = function(x, ...) {
         panel.qqmath(x, ...)
         panel.qqmathline(x, ...)
       })
```


Testing for normality using normal Q-Q plots collapsing over all Vines;

```{r}
qqmath(~ FreshWeight, data=all_fruit_data,
       distribution = function(p) qnorm(p, mean=0, sd=1), main="Normal Q-Q Plot",
       ylab="Sample Quantiles", xlab="Theoretical quantiles",
       scales=list(alternating=FALSE), between=list(x=0.3, y=0.3),
       breaks=30, pch=16, cex=0.5, aspect=1,
      prepanel = prepanel.qqmathline,
       panel = function(x, ...) {
         panel.qqmath(x, ...)
         panel.qqmathline(x, ...)
       })
```



```{r scratchpad, echo=FALSE, eval=FALSE}
xyplot( DryMatter ~ FreshWeight | factor(VineUUID), data=all_fruit_data, scales=list(alternating=FALSE), between=list(x=0.3, y=0.3), breaks=30, layout=c(3,3), pch=16, cex=0.3)


summary(lm(Reaction ~ Days, sleepstudy))
summary(lmer(Reaction ~ Days + (Days | Subject), sleepstudy))


xyplot( DryMatter ~ FreshWeightSlice | factor(VineUUID), data=all_fruit_data, scales=list(alternating=FALSE), between=list(x=0.3, y=0.3), breaks=30, layout=c(3,3), pch=16, cex=0.3)


knitr::kable(with(all_fruit_data, tapply(FreshWeight,  VineUUID, length)), col.names=c("N"))


with(all_fruit_data, tapply(FreshWeight,  VineUUID, shapiro.test))

#
## Anova
#
m1 <- aov(FreshWeight ~ VineUUID, data=all_fruit_data)
summary(m1)
sqrt(summary(m1)[[1]][[3]][2])

#
## sleepstudy
#
xyplot(Reaction ~ 1 + Days | Subject , data=sleepstudy, layout=c(9,2),
       panel=function(x,y, subscripts, groups){
         panel.points(x,y)
         panel.lmline(x,y)
       })

#
## Test for normality
#
replicate(10000, shapiro.test(rt(3, 4))$p) %>%  hist
replicate(1000, shapiro.test(sample(all_fruit_data$FreshWeight, 100, replace=TRUE))$p) %>%  hist


#
## Power simulation 
#
## https://github.com/PlantandFoodResearch/RNASeq_community/blob/master/Workshop_March_2018/presentations/day-2/04_session/exercises/simulation.Rmd

n <- 60

## Simulate two sample, one sided
est_power_one <- power.t.test(n=n, sd=20, power=0.8, type="two.sample", alternative="one.sided")


set.seed(42)
pvals <- replicate(100000, {
  X1 <- rnorm(n, 110, 20)
  X2 <- rnorm(n, 110 + est_power_one$delta, 20)

  t.test(X1, X2, alternative="less")$p.value
})

Sens <- sum(pvals <=0.05)/length(pvals)
print(Sens)

## Simulate two sample, two sided
est_power_two <- power.t.test(n=40, sd=20, power=0.8, type="two.sample", alternative="two.sided")


set.seed(42)
pvals <- replicate(100000, {
  X1 <- rnorm(40, 110, 20)
  X2 <- rnorm(40, 110 + est_power_two$delta, 20)

  t.test(X1, X2, alternative="two.sided")$p.value
})

Sens <- sum(pvals <=0.05)/length(pvals)
print(Sens)

## Simulate two sample, two sided
# create user-defined function to generate and analyze data
t_func <- function(simNum, N, d) {
    x1 <- rnorm(N, 0, 20)
    x2 <- rnorm(N, d, 20)

    t <- t.test(x1, x2, alternative="two.sided", var.equal=TRUE)  # run t-test on generated data
    stat <- t$statistic
    p <- t$p.value

    return(c(t=stat, p=p, sig=(p <= .05)))
        # return a named vector with the results we want to keep
}

d <- power.t.test(n=40, sd=20, power=0.8, type="two.sample", alternative="two.sided")$delta
power_ttest <- run_test(t_func, n.iter=10000, output='data.frame', N=40, d=d)  # simulate data
results(power_ttest) %>%
    summarise(power=mean(sig))


## Simulate two sample, one sided
# create user-defined function to generate and analyze data
t_func <- function(simNum, N, d) {
    x1 <- rnorm(N, 0, 20)
    x2 <- rnorm(N, d, 20)

    t <- t.test(x1, x2, alternative="less", var.equal=TRUE)  # run t-test on generated data
    stat <- t$statistic
    p <- t$p.value

    return(c(t=stat, p=p, sig=(p <= .05)))
        # return a named vector with the results we want to keep
}

d <- power.t.test(n=40, sd=20, power=0.8, type="two.sample", alternative="one.sided")$delta
power_ttest <- run_test(t_func, n.iter=10000, output='data.frame', N=40, d=d)  # simulate data
results(power_ttest) %>%
    summarise(power=mean(sig))


## Simulate one sample, one sided
# create user-defined function to generate and analyze data
t_func <- function(simNum, N, d) {
    x2 <- rnorm(N, d, 20)

    t <- t.test(x2, mu=0, alternative="greater", var.equal=TRUE)  # run t-test on generated data
    stat <- t$statistic
    p <- t$p.value

    return(c(t=stat, p=p, sig=(p <= .05)))
        # return a named vector with the results we want to keep
}

d <- power.t.test(n=40, sd=20, power=0.8, type="one.sample", alternative="one.sided")$delta
power_ttest <- run_test(t_func, n.iter=10000, output='data.frame', N=40, d=d)  # simulate data
results(power_ttest) %>%
    summarise(power=mean(sig))

X <- rnorm(1000, 100, 20)
hist(replicate(10000,  sd(sample(X, 60))), breaks=30)
qqplot(replicate(10000,  var(sample(X, 40))), rchisq(10000, 40-1))
abline(0,1)


ggplot(data.frame(eta=predict(m2,type="link"),pearson=residuals(m2,type="pearson")),
      aes(x=eta,y=pearson)) +
    geom_point() +
    theme_bw()


#
## Bootstraps
#

tmp <- all_fruit_data[all_fruit_data$VineUUID%in%"Vine 2" & !is.na(all_fruit_data$FreshWeight), ]

#sample(tmp$FreshWeight, 40)

hist(replicate(10000,  mean(sample(tmp$FreshWeight, 40))), breaks=30)
hist(replicate(10000,  sd(sample(tmp$FreshWeight, 40))), breaks=30)

qqplot(replicate(10000,  var(sample(tmp$FreshWeight, 40))), rchisq(1000, 40-1))
abline(0,1)


hist(replicate(10000,  mean(sample(tmp$FreshWeight, 60))), breaks=30)
hist(replicate(10000,  sd(sample(tmp$FreshWeight, 60))), breaks=30)
```